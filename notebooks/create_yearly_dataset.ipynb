{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = pd.read_csv('../waqi_data/waqi-covid19-airqualitydata-2023Q1.csv', skiprows=4)\n",
    "q2 = pd.read_csv('../waqi_data/waqi-covid19-airqualitydata-2023Q2.csv', skiprows=4)\n",
    "q3 = pd.read_csv('../waqi_data/waqi-covid19-airqualitydata-2023Q3.csv', skiprows=4)\n",
    "q4 = pd.read_csv('../waqi_data/waqi-covid19-airqualitydata-2023Q4.csv', skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-04-02',\n",
       " '2023-03-27',\n",
       " '2023-03-27',\n",
       " '2023-07-02',\n",
       " '2023-06-26',\n",
       " '2023-10-01',\n",
       " '2023-09-25',\n",
       " '2023-12-31')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.Date.max(),q2.Date.min(), q2.Date.min(),q2.Date.max(), q3.Date.min(),q3.Date.max(),q4.Date.min(), q4.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-04-17'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all the dataframes into a single dataframe\n",
    "# merged_df = pd.concat([q1, q2, q3, q4], ignore_index=True)\n",
    "\n",
    "merged_df = pd.read_csv('../waqi-covid19-airqualitydata-2025.csv', skiprows=4)\n",
    "\n",
    "\n",
    "\n",
    "merged_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Country', 'City', 'Specie', 'count', 'min', 'max', 'median',\n",
       "       'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "d_e_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h_u_m_i_d_i_t_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_m_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_m_1_0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_m_2_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_r_e_s_s_u_r_e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t_e_m_p_e_r_a_t_u_r_e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "w_i_n_d_-_g_u_s_t",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "w_i_n_d_-_s_p_e_e_d",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "40871fc7-a7c4-4487-a2b1-8338f29e7846",
       "rows": [
        [
         "0",
         "2022-12-26",
         "NP",
         "Kathmandu",
         "5.0",
         "73.5",
         "130.0",
         "51.0",
         "143.0",
         "1020.0",
         "10.0",
         null,
         "0.7"
        ],
        [
         "1",
         "2022-12-27",
         "NP",
         "Kathmandu",
         "3.0",
         "75.9",
         "143.0",
         "51.0",
         "151.0",
         "1017.0",
         "8.6",
         null,
         "0.7"
        ],
        [
         "2",
         "2022-12-28",
         "NP",
         "Kathmandu",
         "3.0",
         "79.6",
         "133.0",
         "52.0",
         "149.0",
         "1017.0",
         "8.5",
         null,
         "1.0"
        ],
        [
         "3",
         "2022-12-29",
         "NP",
         "Kathmandu",
         "4.5",
         "81.4",
         "157.0",
         "58.0",
         "163.0",
         "1020.0",
         "8.3",
         null,
         "0.7"
        ],
        [
         "4",
         "2022-12-30",
         "NP",
         "Kathmandu",
         "5.0",
         "81.9",
         "158.0",
         "58.0",
         "163.0",
         "1022.0",
         "8.0",
         null,
         "0.6"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>d_e_w</th>\n",
       "      <th>h_u_m_i_d_i_t_y</th>\n",
       "      <th>p_m_1</th>\n",
       "      <th>p_m_1_0</th>\n",
       "      <th>p_m_2_5</th>\n",
       "      <th>p_r_e_s_s_u_r_e</th>\n",
       "      <th>t_e_m_p_e_r_a_t_u_r_e</th>\n",
       "      <th>w_i_n_d_-_g_u_s_t</th>\n",
       "      <th>w_i_n_d_-_s_p_e_e_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>NP</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>NP</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.9</td>\n",
       "      <td>143.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>NP</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>133.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>NP</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>4.5</td>\n",
       "      <td>81.4</td>\n",
       "      <td>157.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>NP</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>158.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Country       City  d_e_w  h_u_m_i_d_i_t_y  p_m_1  p_m_1_0  \\\n",
       "0  2022-12-26      NP  Kathmandu    5.0             73.5  130.0     51.0   \n",
       "1  2022-12-27      NP  Kathmandu    3.0             75.9  143.0     51.0   \n",
       "2  2022-12-28      NP  Kathmandu    3.0             79.6  133.0     52.0   \n",
       "3  2022-12-29      NP  Kathmandu    4.5             81.4  157.0     58.0   \n",
       "4  2022-12-30      NP  Kathmandu    5.0             81.9  158.0     58.0   \n",
       "\n",
       "   p_m_2_5  p_r_e_s_s_u_r_e  t_e_m_p_e_r_a_t_u_r_e  w_i_n_d_-_g_u_s_t  \\\n",
       "0    143.0           1020.0                   10.0                NaN   \n",
       "1    151.0           1017.0                    8.6                NaN   \n",
       "2    149.0           1017.0                    8.5                NaN   \n",
       "3    163.0           1020.0                    8.3                NaN   \n",
       "4    163.0           1022.0                    8.0                NaN   \n",
       "\n",
       "   w_i_n_d_-_s_p_e_e_d  \n",
       "0                  0.7  \n",
       "1                  0.7  \n",
       "2                  1.0  \n",
       "3                  0.7  \n",
       "4                  0.6  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_city_data(df):\n",
    "    # Convert 'Date' column to datetime\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "    \n",
    "    # Get unique cities\n",
    "    cities = df[df['Country'] == 'NP']['City'].unique()\n",
    "    \n",
    "    # Dictionary to store the processed dataframes\n",
    "    city_dataframes = {}\n",
    "    \n",
    "    for city in cities:\n",
    "        city_df = df[df['City'] == city]\n",
    "        \n",
    "        # Pivot the dataframe to create new columns for each specie\n",
    "        city_pivot = city_df.pivot_table(index=['Date', 'Country', 'City'], columns='Specie', values='median', aggfunc='first')\n",
    "        \n",
    "        # Flatten the multi-level columns\n",
    "        city_pivot.columns = ['_'.join(col).strip() for col in city_pivot.columns.values]\n",
    "        \n",
    "        # Reset the index to make 'Date', 'Country', and 'City' columns again\n",
    "        city_pivot.reset_index(inplace=True)\n",
    "        \n",
    "        # Store the processed dataframe in the dictionary\n",
    "        city_dataframes[city] = city_pivot\n",
    "    \n",
    "    return city_dataframes\n",
    "\n",
    "# Process the data for all cities in merged_df\n",
    "city_dataframes = process_city_data(merged_df)\n",
    "\n",
    "# Example: Access the processed dataframe for Kathmandu\n",
    "ktm_city_pivot = city_dataframes['Kathmandu']\n",
    "ktm_city_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktm_city_pivot.sort_values('Date', inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-07-03', '2023-07-04', '2023-07-05', '2023-07-06',\n",
       "               '2023-07-07', '2023-07-08', '2023-07-09', '2023-07-10',\n",
       "               '2023-07-11', '2023-07-12', '2023-07-13', '2023-07-14',\n",
       "               '2023-07-15', '2023-07-16', '2023-07-17', '2023-07-18',\n",
       "               '2023-07-19', '2023-07-20', '2023-07-21', '2023-07-22',\n",
       "               '2023-07-23', '2023-07-24', '2023-07-25', '2023-07-26',\n",
       "               '2023-07-27', '2023-07-28', '2023-07-29', '2023-07-30',\n",
       "               '2023-07-31', '2023-08-01', '2023-08-02', '2023-08-03',\n",
       "               '2023-08-04', '2023-08-05', '2023-08-06', '2023-08-07',\n",
       "               '2023-08-08', '2023-08-09', '2023-08-10', '2023-08-11',\n",
       "               '2023-08-12', '2023-08-13', '2023-08-14', '2023-08-15',\n",
       "               '2023-08-16', '2023-08-17', '2023-08-18', '2023-08-19',\n",
       "               '2023-08-20', '2023-08-21', '2023-08-22', '2023-08-23',\n",
       "               '2023-08-24', '2023-08-25', '2023-08-26', '2023-08-27',\n",
       "               '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31',\n",
       "               '2023-09-01', '2023-09-02', '2023-09-03', '2023-09-04',\n",
       "               '2023-09-05', '2023-09-06', '2023-09-07', '2023-09-08',\n",
       "               '2023-09-09', '2023-09-10', '2023-09-11', '2023-09-12',\n",
       "               '2023-09-13', '2023-09-14', '2023-09-15', '2023-09-16',\n",
       "               '2023-09-17', '2023-09-18', '2023-09-19', '2023-09-20',\n",
       "               '2023-09-21', '2023-09-22', '2023-09-23', '2023-09-24'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime\n",
    "ktm_city_pivot['Date'] = pd.to_datetime(ktm_city_pivot['Date'])\n",
    "\n",
    "# Create a date range from the minimum to the maximum date in the dataframe\n",
    "full_date_range = pd.date_range(start=ktm_city_pivot['Date'].min(), end=ktm_city_pivot['Date'].max())\n",
    "\n",
    "# Find the missing dates by comparing the full date range with the dates in the dataframe\n",
    "missing_dates = full_date_range.difference(ktm_city_pivot['Date'])\n",
    "\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                      0\n",
       "Country                   0\n",
       "City                      0\n",
       "d_e_w                    42\n",
       "h_u_m_i_d_i_t_y           9\n",
       "p_m_1                    17\n",
       "p_m_1_0                  17\n",
       "p_m_2_5                  17\n",
       "p_r_e_s_s_u_r_e          42\n",
       "t_e_m_p_e_r_a_t_u_r_e     9\n",
       "w_i_n_d_-_s_p_e_e_d       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokhara_data = city_dataframes['Pokhara']\n",
    "\n",
    "# Create a date range from the minimum to the maximum date in the dataframe\n",
    "full_date_range = pd.date_range(start=pokhara_data['Date'].min(), end=pokhara_data['Date'].max())\n",
    "\n",
    "# Find the missing dates by comparing the full date range with the dates in the dataframe\n",
    "missing_dates = full_date_range.difference(pokhara_data['Date'])\n",
    "\n",
    "pokhara_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-03-15', '2023-03-16', '2023-03-17', '2023-03-18',\n",
       "               '2023-03-19', '2023-03-20', '2023-03-21', '2023-03-22',\n",
       "               '2023-03-23', '2023-03-24',\n",
       "               ...\n",
       "               '2023-09-15', '2023-09-16', '2023-09-17', '2023-09-18',\n",
       "               '2023-09-19', '2023-09-20', '2023-09-21', '2023-09-22',\n",
       "               '2023-09-23', '2023-09-24'],\n",
       "              dtype='datetime64[ns]', length=107, freq=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Biratnagar_data = city_dataframes['Biratnagar']\n",
    "\n",
    "# Create a date range from the minimum to the maximum date in the dataframe\n",
    "full_date_range = pd.date_range(start=Biratnagar_data['Date'].min(), end=Biratnagar_data['Date'].max())\n",
    "\n",
    "# Find the missing dates by comparing the full date range with the dates in the dataframe\n",
    "missing_dates = full_date_range.difference(Biratnagar_data['Date'])\n",
    "\n",
    "Biratnagar_data.shape\n",
    "\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code to convert and create the yearly dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the quarterly data\n",
    "\n",
    "q1 = pd.read_csv('../year_2019/waqi-covid19-airqualitydata-2019Q1.csv', skiprows=4)\n",
    "q2 = pd.read_csv('../year_2019/waqi-covid19-airqualitydata-2019Q2.csv', skiprows=4)\n",
    "q3 = pd.read_csv('../year_2019/waqi-covid19-airqualitydata-2019Q3.csv', skiprows=4)\n",
    "q4 = pd.read_csv('../year_2019/waqi-covid19-airqualitydata-2019Q4.csv', skiprows=4)\n",
    "\n",
    "# Combine all quarterly data into a single DataFrame\n",
    "\n",
    "merged_df = pd.concat([q1, q2, q3, q4], ignore_index=True)\n",
    "# merged_df = pd.read_csv('../datafiles/waqi-covid19-airqualitydata-.csv', skiprows=4)\n",
    "\n",
    "# merged_df = pd.read_csv('../waqi-covid19-airqualitydata-2025.csv', skiprows=4)\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "\n",
    "# Filter data for Nepal\n",
    "nepal_df = merged_df[merged_df['Country'] == 'NP']\n",
    "\n",
    "# Get unique cities in Nepal\n",
    "cities = nepal_df['City'].unique()\n",
    "\n",
    "# Define the date range for the entire year \n",
    "date_range = pd.date_range(start=merged_df['Date'].min(), end=merged_df['Date'].max(), freq='D')\n",
    "\n",
    "# Function to process and save city data\n",
    "def process_and_save_city_data(city_df, city_name):\n",
    "    # Pivot the dataframe to create columns for each specie\n",
    "    city_pivot = city_df.pivot_table(index='Date', columns='Specie', values='median', aggfunc='first')\n",
    "    \n",
    "    # Reindex to include all dates in  and fill missing values\n",
    "    city_pivot = city_pivot.reindex(date_range)\n",
    "    \n",
    "    # Reset index to make 'Date' a column\n",
    "    city_pivot.reset_index(inplace=True)\n",
    "    city_pivot.rename(columns={'index': 'Date'}, inplace=True)\n",
    "    \n",
    "    # Save the processed data to a CSV file\n",
    "    city_pivot.to_csv(f'../year_2019/{city_name}_2019.csv', index=False)\n",
    "    \n",
    "    return pd.DataFrame(city_pivot)\n",
    "\n",
    "# Process and save data for each city\n",
    "for city in cities:\n",
    "    city_df = nepal_df[nepal_df['City'] == city]\n",
    "    process_and_save_city_data(city_df, city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../year_2019/Kathmandu_2019.csv')\n",
    "\n",
    "df.drop(columns=['wind speed','wind-gust'], inplace=True)\n",
    "\n",
    "df.to_csv('../year_2019/Kathmandu_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'dew', 'humidity', 'pm1', 'pm10', 'pm25', 'pressure',\n",
       "       'temperature', 'wind-gust', 'wind-speed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../year_2021/Kathmandu_2021.csv')\n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
